# Kizuna Engine: An√°lisis de Arquitectura y Visi√≥n

Este documento analiza el estado actual de Kizuna Engine, identifica problemas cr√≠ticos en la implementaci√≥n y propone la arquitectura ideal para cumplir con la visi√≥n de "Motor de Encarnaci√≥n Universal".

## 1. Arquitectura Actual (Estado Actual)
La arquitectura actual est√° dise√±ada como un sistema de streaming multimodal (Audio + Video) full-duplex utilizando WebSockets para conectar un frontend React con un backend FastAPI que orquesta la API de Gemini Live.

### Backend (backend/app/)
- **Tecnolog√≠a**: Python, FastAPI, Uvicorn, google-genai SDK.
- **Orquestaci√≥n de Sesi√≥n**: La l√≥gica WebSocket reside en `main.py`, utilizando `asyncio.TaskGroup` para gestionar simult√°neamente:
    - `audio_session.send_to_gemini`: Streaming de audio upstream.
    - `audio_session.receive_from_gemini`: Streaming downstream.
    - `subconscious_mind.start`: An√°lisis paralelo de sentimientos.
- **Flujo de Datos**:
    1. **Recepci√≥n Multimodal (Client -> Gemini)**:
       - **Audio**: Recibe audio PCM (16kHz, 16-bit, mono) con buffering de ~100ms.
       - **Visi√≥n**: Recibe frames JPEG base64 (max 480px, calidad 0.5) para an√°lisis visual.
       - **Bio-Feedback**: Endpoint `/api/bio/submit` ingesta BPM para modular hints del sistema (v√≠a `SubconsciousMind`).
    2. **Env√≠o (Gemini -> Client)**: Recibe chunks de audio y texto de Gemini en tiempo real y los reenv√≠a al cliente mediante un protocolo JSON personalizado (`{'type': 'audio', ...}`, `{'type': 'turn_complete'}`).
- **Model Waterfall**: Implementa estrategia de fallback (Cascada) en `SubconsciousMind` y `RitualService`. Si un modelo devuelve error 429 (Rate Limit), el sistema intenta autom√°ticamente con el siguiente en la lista configurada (`settings.MODEL_SUBCONSCIOUS`), asegurando continuidad operativa.
- **Memoria y Mente**:
    - **RAG (Soul Assembler)**: Inyecta episodios recientes (`MemoryEpisodeNode`) y el √∫ltimo sue√±o (`DreamNode`) en el prompt del sistema al iniciar sesi√≥n.
    - **Mente Subconsciente**: Proceso paralelo que analiza transcripciones en tiempo real para generar "System Hints" (emocionales o contextuales) y consolidar memorias.
    - **Sleep Manager**: Gestiona el ciclo de sue√±o REM. Persiste la intenci√≥n de consolidaci√≥n en Redis (`sleep_intent:*`) y asegura que las memorias se guarden incluso ante reinicios o desconexiones, con un timeout de shutdown de 10s.

### Frontend (frontend/src/)
- **Tecnolog√≠a**: React, TypeScript, Vite.
- **Captura de Audio**: Utiliza AudioWorklet (`pcm-processor.js`) para procesar audio crudo (PCM 16-bit) directamente en un hilo separado.
- **Gesti√≥n de Audio (AudioStreamManager)**:
    - **Jitter Buffer Din√°mico**: Implementa un buffer el√°stico (objetivo 60ms). Si la latencia sube (>200ms), acelera la reproducci√≥n (1.05x) para alcanzar el tiempo real sin cortes bruscos ("catch-up").
- **Visi√≥n (UseVision)**: Hook `useVision` permite capturar frames de c√°mara o pantalla, con throttling agresivo para no saturar el WebSocket.
- **Estrategia de Conexi√≥n**: Implementa una filosof√≠a de "Conexi√≥n Indestructible". No se desconecta autom√°ticamente ante errores o eventos `onclose` del socket.

--------------------------------------------------------------------------------

## 2. Historial de Problemas y Correcciones

### ‚úÖ SOLUCIONADO: El Bucle de Retroalimentaci√≥n de Audio (Feedback Loop)
Anteriormente, en `frontend/src/hooks/useLiveAPI.ts`, exist√≠a una conexi√≥n err√≥nea que conectaba el micr√≥fono directamente a los altavoces: `source.connect(ctx.destination);`
**Estado Actual**: El problema ha sido corregido. La l√≠nea problem√°tica fue eliminada, asegurando que el audio del micr√≥fono solo se env√≠e al AudioWorklet para su transmisi√≥n al backend.

### ‚úÖ SOLUCIONADO: Limitaci√≥n Unimodal (Visi√≥n Implementada)
Originalmente, Kizuna solo transmit√≠a audio.
**Estado Actual**: Se ha implementado el pipeline de visi√≥n. El frontend captura frames (JPEG comprimido) y el backend (`audio_session.py`) los enruta a la sesi√≥n multimodal de Gemini, permitiendo a la IA "ver" y comentar sobre el entorno.

### üü° Estado de Transici√≥n: Memoria Epist√©mica H√≠brida (Local/Nube)
Actualmente, se ha implementado una soluci√≥n **semi-aplicada** que sienta las bases para el futuro RAG en la nube.
- **Implementaci√≥n Actual**: Se utiliza `LocalSoulRepository` (basado en JSON) para simular la estructura de datos de un Grafo de Conocimiento.
- **Persistencia**: `SleepManager` y `Redis` aseguran que la consolidaci√≥n de memoria (sue√±os) ocurra de manera confiable al terminar la sesi√≥n.
- **Estrategia**: El sistema funciona 100% local para desarrollo √°gil, pero la arquitectura (`SoulRepository` interface) est√° dise√±ada para cambiar a **Google Cloud Spanner**.

--------------------------------------------------------------------------------

## 3. Arquitectura Propuesta (La Visi√≥n Kizuna)
Para lograr el "Motor de Encarnaci√≥n Universal", la arquitectura debe evolucionar hacia un sistema multimodal con memoria persistente distribuida.

### A. Flujo de Audio Full-Duplex (‚úÖ IMPLEMENTADO)
El sistema actual cumple con el objetivo de latencia total (boca-a-o√≠do) de 400ms-600ms.
1. **Frontend (Microphone)**: Microphone -> AudioContext -> AudioWorklet -> WebSocket.
2. **Backend (Routing)**: WebSocket -> Buffer (100ms) -> Gemini Live Session.
3. **Frontend (Speaker)**: WebSocket -> Decode Base64 -> Jitter Buffer (Dynamic) -> AudioContext.destination.

### B. Sistema de Memoria Epist√©mica (Deep Memory) - (‚úÖ IMPLEMENTADO - FASE LOCAL)
La infraestructura para que Kizuna recuerde hechos est√° activa en modo Local:
1. **RAG Contextual**: `SoulAssembler` recupera episodios recientes y sue√±os pasados.
2. **Mente Subconsciente**: `SubconsciousMind` analiza en segundo plano usando un "Waterfall" de modelos para robustez.
3. **Bio-Feedback**: Ingesta de se√±ales biol√≥gicas (BPM) para modular la respuesta emocional en tiempo real.

### C. Percepci√≥n Multimodal (Visi√≥n) (‚úÖ IMPLEMENTADO)
Para que Kizuna "vea":
1. **Captura de Video**: El frontend captura frames (c√°mara o pantalla).
2. **Env√≠o por WebSocket**: Mensajes JSON `{ "type": "image", ... }`.
3. **Integraci√≥n Backend**: `session.send(input={"data": image_bytes, "mime_type": "image/jpeg"})`.

### D. Conexi√≥n "Indestructible" (‚úÖ IMPLEMENTADO)
La l√≥gica actual asegura que la conexi√≥n nunca se cierra por iniciativa del servidor, salvo error fatal irrecuperable. La IA espera pacientemente en silencio.
