# Kizuna Engine: An√°lisis de Arquitectura y Visi√≥n

Este documento analiza el estado actual de Kizuna Engine, identifica problemas cr√≠ticos en la implementaci√≥n y propone la arquitectura ideal para cumplir con la visi√≥n de "Motor de Encarnaci√≥n Universal".

## 1. Arquitectura Actual (Estado Actual)
La arquitectura actual est√° dise√±ada como un sistema de streaming de audio full-duplex utilizando WebSockets para conectar un frontend React con un backend FastAPI que orquesta la API de Gemini Live.

### Backend (backend/app/)
- **Tecnolog√≠a**: Python, FastAPI, Uvicorn, google-genai SDK.
- **Flujo de Datos**:
    1. **Recepci√≥n (Client -> Gemini)**: Recibe audio PCM (16kHz, 16-bit, mono) a trav√©s de WebSocket.
    2. **Buffering**: Implementa un buffer inteligente de ~100ms (3200 bytes) antes de enviar a Gemini. Esto es crucial para balancear latencia y carga de red, evitando saturar la API con paquetes diminutos.
    3. **Env√≠o (Gemini -> Client)**: Recibe chunks de audio y texto de Gemini en tiempo real y los reenv√≠a al cliente mediante un protocolo JSON personalizado (`{'type': 'audio', ...}`, `{'type': 'turn_complete'}`).
- **Gesti√≥n de Conexi√≥n**: Utiliza `asyncio.TaskGroup` para manejar tareas de env√≠o y recepci√≥n simult√°neamente, asegurando que la desconexi√≥n en un sentido cierre limpiamente ambos lados.
- **Modelo**: Configurado para usar `gemini-2.5-flash-native-audio-preview-12-2025`.
- **Memoria y Mente**: Implementaci√≥n H√≠brida Local (`LocalSoulRepository`) activa. Simula la estructura de grafos de Google Cloud Spanner utilizando JSON local para persistencia de episodios, hechos y resonancia emocional.

### Frontend (frontend/src/)
- **Tecnolog√≠a**: React, TypeScript, Vite.
- **Captura de Audio**: Utiliza AudioWorklet (`pcm-processor.js`) para procesar audio crudo (PCM 16-bit) directamente en un hilo separado, evitando bloqueos en la UI.
- **Gesti√≥n de Estado**: El hook `useLiveAPI` mantiene referencias persistentes (`useRef`) a los contextos de audio y sockets para evitar reconexiones innecesarias durante re-renderizados de React.
- **Estrategia de Conexi√≥n**: Implementa una filosof√≠a de "Conexi√≥n Indestructible". No se desconecta autom√°ticamente ante errores o eventos `onclose` del socket, permitiendo reconexiones o manejo manual para preservar la "presencia" de la IA.

--------------------------------------------------------------------------------

## 2. Historial de Problemas y Correcciones

### ‚úÖ SOLUCIONADO: El Bucle de Retroalimentaci√≥n de Audio (Feedback Loop)
Anteriormente, en `frontend/src/hooks/useLiveAPI.ts`, exist√≠a una conexi√≥n err√≥nea que conectaba el micr√≥fono directamente a los altavoces: `source.connect(ctx.destination);`
**Estado Actual**: El problema ha sido corregido. La l√≠nea problem√°tica fue eliminada, asegurando que el audio del micr√≥fono solo se env√≠e al AudioWorklet para su transmisi√≥n al backend, evitando el eco y el feedback infinito.

### üü° Estado de Transici√≥n: Memoria Epist√©mica H√≠brida (Local/Nube)
Originalmente, Kizuna carec√≠a de memoria a largo plazo. Actualmente, se ha implementado una soluci√≥n **semi-aplicada** que sienta las bases para el futuro RAG en la nube.
- **Implementaci√≥n Actual**: Se utiliza `LocalSoulRepository` (basado en JSON) para simular la estructura de datos de un Grafo de Conocimiento (Usuarios, Agentes, Episodios, Hechos, Resonancia).
- **Mente Subconsciente**: El servicio `SubconsciousMind` opera en segundo plano analizando transcripciones para detectar emociones y generar "insights" que se guardan localmente.
- **Estrategia**: El sistema funciona 100% local para desarrollo √°gil, pero la arquitectura (`SoulRepository` interface) est√° dise√±ada para cambiar a **Google Cloud Spanner** sin modificar la l√≥gica de negocio cuando el proyecto entre en fase de producci√≥n.
- **Impacto**: Kizuna ya puede "recordar" interacciones pasadas y ajustar su personalidad din√°micamente (`SoulAssembler`) basado en la afinidad acumulada localmente.

### üü° Limitaci√≥n: Unimodalidad (Solo Audio)
La implementaci√≥n actual solo transmite audio.
- **Visi√≥n**: Kizuna debe "ver" el entorno para comentar sobre √©l (ropa, desorden, clima).
- **Estado**: El c√≥digo de WebSocket y el procesador de Gemini est√°n preparados para texto y audio, pero no hay flujo de video implementado desde el cliente.

--------------------------------------------------------------------------------

## 3. Arquitectura Propuesta (La Visi√≥n Kizuna)
Para lograr el "Motor de Encarnaci√≥n Universal", la arquitectura debe evolucionar hacia un sistema multimodal con memoria persistente distribuida.

### A. Flujo de Audio Full-Duplex (‚úÖ IMPLEMENTADO)
El sistema actual cumple con el objetivo de latencia total (boca-a-o√≠do) de 400ms-600ms.
1. **Frontend (Microphone)**: Microphone -> AudioContext -> AudioWorklet -> WebSocket. (SIN conexi√≥n a destination).
2. **Backend (Routing)**: WebSocket -> Buffer (100ms) -> Gemini Live Session.
3. **Frontend (Speaker)**: WebSocket -> Decode Base64 -> AudioBufferSource -> AudioContext.destination.
*Nota: La capacidad de interrupci√≥n (Barge-in) es posible gracias a la arquitectura full-duplex.*

### B. Sistema de Memoria Epist√©mica (Deep Memory) - (üîÑ SEMI-APLICADO)
La infraestructura para que Kizuna recuerde hechos est√° activa en modo Local:
1. **Base de Datos Vectorial (RAG)**: Actualmente implementada como `LocalSoulRepository` (JSON). Esta estructura espejo permite validar el modelo de datos (Grafo) antes de la migraci√≥n final a Google Cloud Spanner.
2. **Inyecci√≥n de Contexto**: Al iniciar una sesi√≥n, `SoulAssembler` consulta el repositorio local para construir un `system_instruction` √∫nico basado en la `Resonance` (afinidad) y los hechos recordados.
3. **Mente Subconsciente**: Un proceso secundario (`SubconsciousMind`) analiza la conversaci√≥n en tiempo real (simulado localmente) para extraer nuevos hechos y emociones, guard√°ndolos en el JSON local para futuras sesiones.

### C. Percepci√≥n Multimodal (Visi√≥n)
Para que Kizuna "vea":
1. **Captura de Video**: El frontend debe capturar frames de video (ej. 1 frame cada 1-2 segundos) usando un Canvas oculto y `canvas.toDataURL()`.
2. **Env√≠o por WebSocket**: Enviar estos frames como mensajes JSON (`{ type: "image", data: "base64..." }`) por el mismo WebSocket existente.
3. **Integraci√≥n Backend**: El backend debe recibir estos mensajes y enviarlos a la sesi√≥n de Gemini Live usando `session.send(input={"data": image_bytes, "mime_type": "image/jpeg"})`.

### D. Conexi√≥n "Indestructible" (‚úÖ IMPLEMENTADO)
La l√≥gica actual asegura que la conexi√≥n nunca se cierra por iniciativa del servidor, salvo error fatal irrecuperable. La IA espera pacientemente en silencio (como una persona en la habitaci√≥n) hasta que el usuario decida interactuar o cerrar la "invocaci√≥n".
