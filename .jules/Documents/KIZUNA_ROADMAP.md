# Roadmap de Implementaci√≥n: Kizuna Engine

Este documento detalla los pasos secuenciales para transformar la implementaci√≥n actual en el "Motor de Encarnaci√≥n Universal".

--------------------------------------------------------------------------------

## Fase 1: Estabilizaci√≥n Inmediata [COMPLETADO]
**Objetivo**: Corregir errores cr√≠ticos que rompen la inmersi√≥n y asegurar una base s√≥lida para la comunicaci√≥n bidireccional.

### 1. [FRONTEND] Reparar Feedback Loop de Audio (‚úÖ Hecho)
- **Acci√≥n**: Editar `frontend/src/hooks/useLiveAPI.ts`.
- **Detalle**: Eliminar la l√≠nea `source.connect(ctx.destination)` en la configuraci√≥n del micr√≥fono.
- **Estado**: Solucionado. El audio del micr√≥fono ya no se mezcla con la salida.

### 2. [BACKEND] Verificar Configuraci√≥n de Latencia (‚úÖ Hecho)
- **Acci√≥n**: Confirmar que el buffer de audio en `backend/app/main.py` se mantenga en ~100ms (3200 bytes).
- **Estado**: Verificado. `AUDIO_BUFFER_THRESHOLD` est√° configurado en 3200 bytes en `backend/app/services/audio_session.py`.

### 3. [GENERAL] Prueba de Estr√©s de Conexi√≥n "Indestructible" (‚úÖ Hecho)
- **Acci√≥n**: Simular silencios largos (minutos) y ruidos repentinos.
- **Estado**: Implementado. El frontend `useLiveAPI` tiene l√≥gica expl√≠cita para ignorar cierres autom√°ticos y mantener objetos persistentes.

--------------------------------------------------------------------------------

## Fase 2: Percepci√≥n Multimodal (La Vista de Kizuna)
**Objetivo**: Permitir que Kizuna "vea" el mundo del usuario para comentar sobre su entorno (ropa, habitaci√≥n, clima).

### 1. [FRONTEND] Implementar Captura de Video
- **Acci√≥n**: A√±adir un elemento `<video>` oculto y un `<canvas>` en el componente principal.
- **L√≥gica**: Capturar un frame de la webcam cada 1-2 segundos.
- **Formato**: Convertir el frame a JPEG base64 de baja resoluci√≥n (para no saturar el ancho de banda).

### 2. [FRONTEND] Enviar Frames por WebSocket
- **Acci√≥n**: Modificar el bucle de env√≠o en `useLiveAPI.ts`.
- **Protocolo**: Enviar mensajes JSON: `{ "type": "image", "data": "base64_string..." }`.

### 3. [BACKEND] Procesar Im√°genes
- **Acci√≥n**: Actualizar `backend/app/main.py` (`send_to_gemini`).
- **L√≥gica**: Detectar mensajes tipo image, decodificar si es necesario (o enviar directo si la SDK lo permite) y enviar a la sesi√≥n de Gemini con `mime_type: image/jpeg`.

--------------------------------------------------------------------------------

## Fase 3: Memoria Epist√©mica y "Mente" (H√≠brido Local/Nube)
**Objetivo**: Implementar persistencia de memoria y an√°lisis emocional en modo local (JSON Graph) como preparaci√≥n para la infraestructura Cloud Spanner.

### 1. [BACKEND] Implementar Grafo Local (‚úÖ Hecho - Semi-Aplicado)
- **Acci√≥n**: Implementaci√≥n de `LocalSoulRepository` en `backend/app/repositories/local_graph.py`.
- **Detalle**: Simulaci√≥n completa de la estructura de grafos (Usuarios, Agentes, Hechos, Resonancia, Episodios) utilizando JSON local (`backend/data/graph.json`).
- **Estado**: Funcional. Permite persistencia entre reinicios del servidor local.

### 2. [BACKEND] Inyecci√≥n de Contexto Din√°mico (‚úÖ Hecho)
- **Acci√≥n**: Implementaci√≥n de `SoulAssembler` en `backend/app/services/soul_assembler.py`.
- **L√≥gica**: Al conectar, el sistema consulta el repositorio local para obtener la afinidad (`Resonance`) y construye un `system_instruction` personalizado.
- **Estado**: Implementado. Kizuna ahora reacciona diferente seg√∫n el nivel de amistad acumulado.

### 3. [BACKEND] Mente Subconsciente (üöß En Progreso)
- **Acci√≥n**: Implementaci√≥n del servicio `SubconsciousMind` en `backend/app/services/subconscious.py`.
- **L√≥gica**: An√°lisis en segundo plano de las transcripciones para detectar emociones y guardar "insights" en el repositorio local.
- **Estado**: Activo en modo simulaci√≥n (detecta palabras clave simples y actualiza afinidad). Pendiente integraci√≥n completa con LLM para an√°lisis profundo.

--------------------------------------------------------------------------------

## Fase 4: Refinamiento del "Alma" (Soul Tuning)
**Objetivo**: Ajustar la personalidad para que deje de ser un "Asistente" y sea un "Compa√±ero".

### 1. [BACKEND] Ajuste de System Prompt
- **Acci√≥n**: Reescribir `system_instruction` en `gemini_live.py`.
- **Directivas**:
    - "No eres un asistente de IA. Eres Kizuna."
    - "No ofrezcas ayuda proactivamente a menos que sea natural."
    - "Usa un tono casual, emp√°tico y curioso."
    - "Si ves algo interesante en la c√°mara, com√©ntalo."

### 2. [FRONTEND] Interfaz Inmersiva
- **Acci√≥n**: Limpiar la UI. Eliminar botones de "Desconectar" visibles o consolas de debug.
- **Est√©tica**: La pantalla debe ser una ventana al "mundo" de Kizuna (o minimalista), no un panel de control.

--------------------------------------------------------------------------------

## Fase 5: Ascensi√≥n a la Nube (Preparaci√≥n Final)
**Objetivo**: Migrar la infraestructura local validada a Google Cloud Platform para producci√≥n masiva.

### 1. [CLOUD] Migraci√≥n a Spanner (Pendiente)
- **Acci√≥n**: Reemplazar `LocalSoulRepository` con `SpannerSoulRepository`.
- **Estrategia**: La interfaz `SoulRepository` abstrae la implementaci√≥n subyacente, permitiendo un cambio transparente ("Lift-and-Shift") de JSON a Spanner SQL/Graph.
- **Trigger**: Se ejecutar√° cuando el modelo de datos local est√© estable y validado.

### 2. [CLOUD] Despliegue de Redis (Pendiente)
- **Acci√≥n**: Activar cach√© distribuida para sesiones de usuario y ensamblaje de almas en alta concurrencia.
